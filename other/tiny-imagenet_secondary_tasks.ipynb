{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4171619c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tim/miniconda3/envs/edsr/lib/python3.6/site-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_size': (3, 224, 224),\n",
       " 'interpolation': 'bicubic',\n",
       " 'mean': (0.485, 0.456, 0.406),\n",
       " 'std': (0.229, 0.224, 0.225),\n",
       " 'crop_pct': 0.875}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib\n",
    "from PIL import Image\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "config = resolve_data_config({}, model=model)\n",
    "transform = create_transform(**config)\n",
    "\n",
    "import timm\n",
    "model = timm.create_model('efficientnet_b0', pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5bcd475d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiny-imagenet was only annotated with wnids like n012345678\n",
    "# but timm's classifiers give simple ids \n",
    "\n",
    "# this file maps the two\n",
    "wnids_to_class_idx = dict()\n",
    "with open(\"wnids_to_class_idx.txt\", 'r') as wnids_to_class_idx_file:\n",
    "    contents = wnids_to_class_idx_file.readlines()\n",
    "    for line in contents:\n",
    "        line = line.strip().split(' ')\n",
    "        wnids_to_class_idx[line[0]] = line[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "17c4b90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maps the tiny-imagenet wnids to the simple ids from above\n",
    "annotations = dict()\n",
    "with open(\"val_annotations.txt\", 'r') as val_annotations:\n",
    "    contents = val_annotations.readlines()\n",
    "    i = 0\n",
    "    for line in contents:\n",
    "        line = line.split('\\t')\n",
    "        annotations[i] = wnids_to_class_idx[line[1]]\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f612027e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run_name: csv filename prefix\n",
    "# base_path: folder where images are located\n",
    "# images should be named like this: f\"{fname_start}{i}{fname_end}\"\n",
    "# that is, fname_start, followed by the index (no padding, i.e. 0, 1, 2,..., 10, ...), followed by fname_end with no spaces\n",
    "\n",
    "# writes a CSV file f\"{run_name}-results.csv\" where each row is\n",
    "# filename, ground truth label, top 5 labels predicted, top 5 probabilities, was top 1 correct?, was one of top 5 correct?\n",
    "def do_classifier_run(run_name, base_path, fname_start, fname_end):\n",
    "    with open(f\"{run_name}-results.csv\", 'w') as outfile:\n",
    "        for i in range(10000):\n",
    "            fname = f\"{fname_start}{i}{fname_end}\"\n",
    "            tensor = transform(Image.open(f\"{base_path}{fname}\")).unsqueeze(0)    \n",
    "            with torch.no_grad():\n",
    "                out = model(tensor)\n",
    "            probabilities = torch.nn.functional.softmax(out[0], dim=0)\n",
    "            top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "\n",
    "            top5_prob = [\"{0:0.5f}\".format(i) for i in top5_prob.tolist()]\n",
    "            top5_prob_string = ','.join(top5_prob)\n",
    "\n",
    "            top5_catid = [str(j) for j in top5_catid.tolist()]\n",
    "            top5_catid_string = ','.join(top5_catid)\n",
    "\n",
    "            top1_correct = annotations[i] == top5_catid[0]\n",
    "            top5_correct = annotations[i] in top5_catid\n",
    "\n",
    "            print(f\"{fname},{annotations[i]},{top5_catid_string},{top5_prob_string},{top1_correct},{top5_correct}\", file=outfile)\n",
    "            if i % 1000 == 0:\n",
    "                print(f\"done {i}/10000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "af60c6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 0/10000\n",
      "done 1000/10000\n",
      "done 2000/10000\n",
      "done 3000/10000\n",
      "done 4000/10000\n",
      "done 5000/10000\n",
      "done 6000/10000\n",
      "done 7000/10000\n",
      "done 8000/10000\n",
      "done 9000/10000\n"
     ]
    }
   ],
   "source": [
    "#do_classifier_run(run_name = \"tiny-imagenet\", base_path = \"EDSR-PyTorch/test/\", fname_start =\"val_\", fname_end=\".png\")\n",
    "do_classifier_run(run_name = \"pretrained_model\", base_path = \"EDSR-PyTorch/experiment/test/results-Demo/\", fname_start =\"val_\", fname_end=\"_x4_SR.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211a60b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
